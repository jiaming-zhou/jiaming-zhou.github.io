<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://jiaming-zhou.github.io/">
        <span class="icon">
            <i class="fas fa-home"></i>
        </span>
        </a>
  
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://jiaming-zhou.github.io/AGNOSTOS">
              Cross-task Manipulation Benchmark for VLAs
            </a> 
            <a class="navbar-item" href="https://teleema.github.io/projects/GLOVER/">
              Open-Vocabulary Grasping
            </a>
          </div>
        </div>
      </div>
  
    </div>
  </nav>


  <title>Mitigating the Human-Robot Domain Discrepancy in Visual Pre-training for Robotic Manipulation</title>
  <link rel="icon" type="image/x-icon" href="static/images/UST.svg.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title" style="font-family: 'Times New Roman', Times, serif;">
                Mitigating the Human-Robot Domain Discrepancy in Visual Pre-training for Robotic Manipulation
            </h1></h1>
            <h2 class="is-size-4" style="font-family: 'Times New Roman', Times, serif;">CVPR 2025</h2>
            <div class="is-size-5 publication-authors" style="font-family: 'Times New Roman', Times, serif;">
              <!-- Paper authors -->
              <span class="author-block">
                <!-- <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Jiaming Zhou</a><sup>*</sup>,</span> -->
                <a href="https://jiaming-zhou.github.io/" target="_blank">Jiaming Zhou</a><sup>1</sup> &nbsp;</span>
                <span class="author-block">
                <a href="https://scholar.google.com/citations?user=arny77IAAAAJ&hl=en" target="_blank">Teli Ma</a><sup>1</sup> &nbsp;</span>
                <span class="author-block">
                <a href="https://scholar.google.com/citations?user=tkUBeeQAAAAJ&hl=en" target="_blank">Kun-Yu Lin</a><sup>2</sup> &nbsp;</span>
                <span class="author-block">
                  <a href="https://openreview.net/profile?id=~Zifan_Wang7" target="_blank">Zifan Wang</a><sup>1</sup> &nbsp;</span>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?hl=en&user=QOwOHZMAAAAJ" target="_blank">Ronghe Qiu</a><sup>1</sup> &nbsp;</span>
                <span class="author-block">
                <a href="https://junweiliang.me" target="_blank">Junwei Liang</a><sup>1,3,&dagger;</sup>
                </span>
                </div>

                  <div class="is-size-5 publication-authors" style="font-family: 'Times New Roman', Times, serif;">
                  <span class="author-block"><sup>1</sup>AI Thrust, The Hong Kong University of Science and Technology (Guangzhou)</span>
                  <span class="author-block"><sup>2</sup>Computer Science and Engineering, Sun Yat-sen University</span>
                  <span class="author-block"><sup>3</sup>CSE, The Hong Kong University of Science and Technology</span>
                  <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
                  <span class="eql-cntrb"><small><br>&dagger; Indicates Corresponding Author</small></span>
                  </div>

                  <div class="column has-text-centered">
                  <div class="publication-links">
                    <!-- Arxiv PDF link -->
                    <span class="link-block">
                    <a href="https://arxiv.org/abs/2406.14235" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                    </a>
                  </span>


                  <!-- Supplementary PDF link -->
                  <!-- <span class="link-block">
                    <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Supplementary</span>
                  </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                  <a href="https://github.com/jiaming-zhou/HumanRobotAlign" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
                </span>

                <!-- Video link -->
                <span class="link-block">
                  <a href="https://youtu.be/cQQ8KiCjRbU" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                  <i class="fas fa-video"></i>
                  </span>
                  <span>Video</span>
                </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2406.14235" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              
              <!-- Media Link -->
              <span class="link-block">
                <a href="https://mp.weixin.qq.com/s/4D58UpJ7g3gmQbRyx0bCwQ" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fas fa-newspaper"></i>
                </span>
                <span>Media</span>
              </a>
            </span>


              </a>
            </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- <div class="container is-max-desktop">
  <h6 class="title is-5" align="center" style="color: #000000">The code, data, and models will be released upon the acceptance of paper.</h6>
</div> -->


<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- <h2 class="title is-3">Video Presentation</h2> -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-three-quarters">
          <div class="publication-video">
            <iframe width="520" height="300" src="https://www.youtube.com/embed/cQQ8KiCjRbU?si=XQXlx6GrOi9I6OLj&amp;start=1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End youtube video -->


<!-- Begin Abstract -->
<section class="section is-light">
    <!-- <div class="container is-max-desktop"> -->
    <!-- <div class="container is-max-widescreen"> -->
      <div class="container is-max-fullhd">
        <div class="columns is-centered">
          <div class="column is-three-quarters"> <!-- 将宽度调整为四分之三 -->
        <div class="box" style="background-color: #f9f9f9; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
          <h2 class="title is-3 has-text-centered" style="font-family: 'Times New Roman', Times, serif;">Abstract</h2>
          <div class="content has-text-justified" style="font-family: 'Times New Roman', Times, serif; font-size: 1.25rem;">
            <p>
              Learning generalizable visual representations across different embodied environments is essential for effective robotic manipulation in real-world scenarios. 
              However, the limited scale and diversity of robot demonstration data pose a significant challenge. 
              Recent research has explored leveraging large-scale human activity data for pre-training, but the substantial morphological differences between humans and robots introduce a significant human-robot domain discrepancy, hindering the generalization of these models to downstream manipulation tasks.
              To overcome this, we propose a novel adaptation paradigm that leverages readily available paired human-robot video data to bridge the domain gap. 
              Our method employs a human-robot contrastive alignment loss to align the semantics of human and robot videos, adapting pre-trained models to the robot domain in a parameter-efficient manner.
              Experiments on 20 simulated tasks across two different benchmarks and five real-world tasks demonstrate significant improvements.
              These results span both single-task and language-conditioned multi-task settings, evaluated using two different pre-trained models.
              Compared to existing pre-trained models, our adaptation method improves the average success rate by over 7% across multiple tasks on both simulated benchmarks and real-world evaluations.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Abstract -->


<!-- Begin Abstract -->
<section class="section is-small">
  <div class="container is-max-fullhd">
    <div class="columns is-centered">
      <div class="column is-three-quarters">
        <div class="box" style="background-color: #f9f9f9; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
          <h2 class="title is-3 has-text-centered" style="font-family: 'Times New Roman', Times, serif;">Motivation</h2>
          <div class="content has-text-justified" style="font-family: 'Times New Roman', Times, serif; font-size: 1.25rem;">
            <p>
              We highlight the human-robot domain discrepancy in visual pre-training for robotic manipulation, and provide a new adaptation paradigm that simultaneously alleviates the domain discrepancy and maintains the versatility of pre-trained models.
            </p>
          </div>
          <div style="text-align: center;">
            <img src="static/images/motivation_v1.jpg" alt="motivation" style="max-width: 100%; border-radius: 10px;">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section is-small">
  <div class="container is-max-fullhd">
    <div class="columns is-centered">
      <div class="column is-three-quarters">
        <div class="box" style="background-color: #f9f9f9; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
          <h2 class="title is-3 has-text-centered" style="font-family: 'Times New Roman', Times, serif;">Method</h2>
          <div class="content has-text-justified" style="font-family: 'Times New Roman', Times, serif; font-size: 1.25rem;">
            <p>
              We propose a Human-Robot Semantic Alignment method, which adapts 
              pre-trained models with parameter-efficient design and exploits a 
              human-robot contrastive alignment loss for effectively mitigating 
              the domain discrepancy;
            </p>
          </div>
          <div style="text-align: center;">
            <img src="static/images/method.jpg" alt="method" style="max-width: 100%; border-radius: 10px;">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section is-small">
  <div class="container is-max-fullhd">
    <div class="columns is-centered">
      <div class="column is-three-quarters">
        <div class="box" style="background-color: #f9f9f9; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
          <h2 class="title is-3 has-text-centered" style="font-family: 'Times New Roman', Times, serif;">Experiments on real-world tasks</h2>
          <div style="text-align: center;">
            <img src="static/images/downstream_real_world.jpg" alt="real_world" style="max-width: 100%; border-radius: 10px;">
          </div>
            <div class="columns is-multiline is-centered" style="margin-top: 20px;">
              <div class="column is-one-third">
                <video controls autoplay loop muted width="100%">
                  <source src="static/videos/put_tennis_in_mug_success_1_720p_3speed.mov" type="video/mp4">

                </video>
              </div>
              <div class="column is-one-third">
                <video controls autoplay loop muted width="100%">
                  <source src="static/videos/put_tennis_in_mug_success_2_720p_3speed.mov" type="video/mp4">

                </video>
              </div>
              <div class="column is-one-third">
                <video controls autoplay loop muted width="100%">
                  <source src="static/videos/put_tennis_in_mug_failure_1_720p_3speed.mov" type="video/mp4">

                </video>
              </div>
            </div>
            <div class="columns is-multiline is-centered" style="margin-top: 20px;">
              <div class="column is-one-third">
                <video controls autoplay loop muted width="100%">
                  <source src="static/videos/stack_cups_failure_1_720p_3speed.mov" type="video/mp4">

                </video>
              </div>
              <div class="column is-one-third">
                <video controls autoplay loop muted width="100%">
                  <source src="static/videos/stack_cups_success_2_720p_3speed.mov" type="video/mp4">

                </video>
              </div>
              <div class="column is-one-third">
                <video controls autoplay loop muted width="100%">
                  <source src="static/videos/stack_cups_failure_1_720p_3speed.mov" type="video/mp4">

                </video>
              </div>
            </div>
            </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section is-small">
  <div class="container is-max-fullhd">
    <div class="columns is-centered">
      <div class="column is-three-quarters">
        <div class="box" style="background-color: #f9f9f9; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
          <h2 class="title is-3 has-text-centered" style="font-family: 'Times New Roman', Times, serif;">Experiments on RLBench</h2>
          <div style="text-align: center;">
            <img src="static/images/downstream_rlbench.jpg" alt="rlbench" style="max-width: 100%; border-radius: 10px;">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- Paper Conclusion -->
<section class="section is-small">
  <div class="container is-max-fullhd">
    <div class="columns is-centered">
      <div class="column is-three-quarters">
        <div class="box" style="background-color: #f9f9f9; border-radius: 10px; box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);">
          <h2 class="title is-3 has-text-centered" style="font-family: 'Times New Roman', Times, serif;">Conclusion</h2>
          <div class="content has-text-justified" style="font-family: 'Times New Roman', Times, serif; font-size: 1.25rem;">
            <p>
              The existing learning paradigm of visual pre-training on human data for robotic manipulation encounters the human-robot domain discrepancy. 
              Our work takes a preliminary attempt to solve this challenging problem.
              In this work, we contribute a new adaptation paradigm by leveraging existing semantic-aligned human-robot video data and proposing an efficient semantic alignment method. 
              In this way, the existing human-data pre-trained models can be efficiently and explicitly adapted to the robot domain, without the need to be tailored for each downstream robotic environment.
              Experiments on 25 robotic manipulation tasks across different environments and different pre-trained models demonstrate the efficacy of our proposed method.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper Conclusion -->



<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content" style="font-family: 'Times New Roman', Times, serif;">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{zhou2024mitigating,
        title={Mitigating the Human-Robot Domain Discrepancy in Visual Pre-training for Robotic Manipulation},
        author={Zhou, Jiaming and Ma, Teli and Lin, Kun-Yu and Qiu, Ronghe and Wang, Zifan and Liang, Junwei},
        journal={arXiv preprint arXiv:2406.14235},
        year={2024}
      }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p style="text-align:center;font-size:small;">
            This page was modified upon the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
